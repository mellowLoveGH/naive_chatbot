{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_tagging_NER_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABFi5n9XfeFs"
      },
      "source": [
        "#!pip install stanfordnlp\n",
        "\n",
        "# http://www.linguisticsweb.org/doku.php?id=linguisticsweb:tutorials:linguistics_tutorials:automaticannotation:stanford_pos_tagger_python\n",
        "# running the Stanford POS Tagger from NLTK\n",
        "#!pip install nltk\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import StanfordTagger\n",
        "\n",
        "# download those files to help POS-tagging\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "\n",
        "import re\n",
        "# remove punctuations from unicode string except apostrophe\n",
        "# split sentence as words / tokenization\n",
        "def word_token(sentence):\n",
        "  #text_tok = nltk.word_tokenize(text_example)\n",
        "  sentence = re.sub(r\"[^\\w\\d'\\s]+\",'',sentence)\n",
        "  #print(sentence)\n",
        "  words = sentence.split(' ')\n",
        "  return words\n",
        "\n",
        "\"\"\"\n",
        "# all tags with the abbreviations\n",
        "CC :\t conjunction, coordinating\n",
        "CD :\t numeral, cardinal\n",
        "DT :\t determiner\n",
        "EX :\t existential\n",
        "FW :\t foreign word\n",
        "IN :\t preposition\n",
        "JJ :\t adjective\n",
        "LS :\t list marker\n",
        "MD :\t modal auxiliary\n",
        "NN :\t noun\n",
        "PDT :\t pre-determiner\n",
        "POS :\t genitive marker\n",
        "PR :\t pronoun\n",
        "RB :\t adverb\n",
        "RP :\t particle\n",
        "SYM :\t symbol\n",
        "UH :\t interjection\n",
        "VB :\t verb\n",
        "WDT :\t WH-determiner\n",
        "WP :\t WH-pronoun\n",
        "WRB :\t Wh-adverb\n",
        "\n",
        "#nltk.help.upenn_tagset()\n",
        "# to print out all tag-set\n",
        "\"\"\"\n",
        "# pos-tagging all words\n",
        "def pos_tagging(sentence):\n",
        "  # there are different tags as above when using Stanford toolkit\n",
        "  tags = {'CC': 'conjunction, coordinating', 'CD': 'numeral, cardinal', 'DT': 'determiner', 'EX': 'existential', 'FW': 'foreign word', 'IN': 'preposition', 'JJ': 'adjective', 'LS': 'list marker', 'MD': 'modal auxiliary', 'NN': 'noun', 'PDT': 'pre-determiner', 'POS': 'genitive marker', 'PR': 'pronoun', 'RB': 'adverb', 'RP': 'particle', 'SYM': 'symbol', 'UH': 'interjection', 'VB': 'verb', 'WDT': 'WH-determiner', 'WP': 'WH-pronoun', 'WRB': 'Wh-adverb'}\n",
        "  words = word_token(text_example)\n",
        "  pos_tagged = nltk.pos_tag(text_tok)\n",
        "  dic = {}\n",
        "  for w, tag in pos_tagged:\n",
        "    tag = tag[:2]\n",
        "    dic[w] = tags[tag]\n",
        "  return dic\n",
        "\n",
        "text_example = \"Avengers: Endgame is a 2019 American superhero film based on the Marvel Comics superhero team the Avengers, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. The movie features an ensemble cast including Robert Downey Jr., Chris Evans, Mark Ruffalo, Chris Hemsworth, and others. (Source: wikipedia).\"\n",
        "pos_tagging(text_example)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwC_E8Lfl2Rq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tex1jxLfSKLC",
        "outputId": "c54177ce-6561-48e6-c29e-af103bb9728e"
      },
      "source": [
        "# https://stackabuse.com/spelling-correction-in-python-with-textblob/\n",
        "# https://pypi.org/project/pyspellchecker/\n",
        "\n",
        "#!pip install pyspellchecker\n",
        "from spellchecker import SpellChecker\n",
        "#!pip install textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "def check_spelling(sentence):\n",
        "  spell = SpellChecker()\n",
        "  words = word_token(sentence)\n",
        "  mistakes = spell.unknown(words)\n",
        "  dic = {}\n",
        "  for w in mistakes:\n",
        "    # spell.candidates(w)\n",
        "    dic[w] = spell.correction(w)\n",
        "  return dic\n",
        "\n",
        "def check_spelling_update(sentence):\n",
        "  words = word_token(sentence)\n",
        "  dic = {}\n",
        "  for w in words:\n",
        "    cor = TextBlob(w)\n",
        "    nw = cor.correct()\n",
        "    nw = str(nw)    \n",
        "    if nw!=w:\n",
        "      dic[w] = nw\n",
        "  return dic\n",
        "\n",
        "def check(sentence):\n",
        "  d1 = check_spelling(sentence)\n",
        "  d2 = check_spelling_update(sentence)\n",
        "  dic = {}\n",
        "  for w in d1:\n",
        "    dic[w] = d1[w]\n",
        "  for w in d2:\n",
        "    dic[w] = d2[w]\n",
        "  return dic\n",
        "\n",
        "# find those words that may be misspelled\n",
        "sentence = 'something is hapenning here, what do you abl about taht'\n",
        "check_spelling(sentence)\n",
        "check_spelling_update(sentence)\n",
        "check(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abl': 'all', 'hapenning': 'happening', 'taht': 'that'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvbSF-n5iVSe",
        "outputId": "cab870b7-a47d-4165-d1e9-db98f02a0b92"
      },
      "source": [
        "#!pip install textblob\n",
        "from textblob import TextBlob\n",
        "textBlb = TextBlob(sentence)\n",
        "textCorrected = textBlb.correct() \n",
        "print(textCorrected)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "something is happening here, what do you all about that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBqhkGkolvn_"
      },
      "source": [
        "\n",
        "# https://www.pluralsight.com/guides/natural-language-processing-named-entity-recognition\n",
        "# NER\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "nltk.download('wordnet')  #download if using this module for the first time\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')    #download if using this module for the first time\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icIL4kSZly6F",
        "outputId": "f7613d10-0c8e-4cb2-e1ab-90a0702bbb1f"
      },
      "source": [
        "textexample = \"Avengers: Endgame is a 2019 American superhero film based on the Marvel Comics superhero team the Avengers, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. The movie features an ensemble cast including Robert Downey Jr., Chris Evans, Mark Ruffalo, Chris Hemsworth, and others. (Source: wikipedia).\"\n",
        "#print(textexample)\n",
        "\n",
        "\n",
        "#Word Tokenization\n",
        "sentences = nltk.sent_tokenize(textexample)\n",
        "tokenized_sentence = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "tokenized_sentence \n",
        "\n",
        "\n",
        "\"\"\"DT: determiner\n",
        "IN: preposition/subordinating conjunction\n",
        "JJ: adjective ‘big’\n",
        "JJR: adjective, comparative ‘bigger’\n",
        "JJS: adjective, superlative ‘biggest’\n",
        "LS: list marker\n",
        "NN: noun, singular ‘desk’\n",
        "NNS: noun plural ‘desks’\n",
        "NNP: proper noun, singular ‘Harrison’\n",
        "NNPS: proper noun, plural ‘Americans’\n",
        "PRP: personal pronoun I, he, she\n",
        "RB: adverb very, silently,\n",
        "UH: interjection\n",
        "VB: verb, base form take\n",
        "VBD: verb, past tense took\"\"\"\n",
        "\n",
        "#Parts of Speech (POS) Tagging\n",
        "pos_tagging_sentences = [nltk.pos_tag(sent) for sent in tokenized_sentence]\n",
        "def preprocess(text):\n",
        "    text = nltk.word_tokenize(text)\n",
        "    text = nltk.pos_tag(text)\n",
        "    return text\n",
        "\n",
        "processed_text = preprocess(textexample)\n",
        "processed_text\n",
        "\n",
        "#Chunking - perform NER analysis.\n",
        "res_chunk = ne_chunk(processed_text)\n",
        "\n",
        "for x in str(res_chunk).split('\\n'):\n",
        "    if '/NN' in x:\n",
        "        print(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Avengers/NNS\n",
            "  Endgame/NN\n",
            "  superhero/NN\n",
            "  film/NN\n",
            "  (ORGANIZATION Marvel/NNP Comics/NNP)\n",
            "  superhero/NN\n",
            "  team/NN\n",
            "  (ORGANIZATION Avengers/NNPS)\n",
            "  (PERSON Marvel/NNP Studios/NNP)\n",
            "  (PERSON Walt/NNP Disney/NNP Studios/NNP)\n",
            "  Motion/NNP\n",
            "  Pictures/NNP\n",
            "  movie/NN\n",
            "  cast/NN\n",
            "  (PERSON Robert/NNP Downey/NNP Jr./NNP)\n",
            "  (PERSON Chris/NNP Evans/NNP)\n",
            "  (PERSON Mark/NNP Ruffalo/NNP)\n",
            "  (PERSON Chris/NNP Hemsworth/NNP)\n",
            "  others/NNS\n",
            "  (PERSON Source/NN)\n",
            "  wikipedia/NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YynjCyghonFv",
        "outputId": "44ffd3d5-76a1-4e69-9bac-b3645578099f"
      },
      "source": [
        "# https://realpython.com/python-nltk-sentiment-analysis/\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "#nltk.download('vader_lexicon')\n",
        "\"\"\"The negative, neutral, and positive scores are related: \n",
        "They all add up to 1 and can’t be negative. \n",
        "The compound score is calculated differently. \n",
        "It’s not just an average, and it can range from -1 to 1.\"\"\"\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(\"Wow, NLTK is really powerful!\")\n",
        "\n",
        "#\n",
        "#nltk.download('twitter_samples')\n",
        "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]\n",
        "from random import shuffle\n",
        "\n",
        "def is_positive(tweet: str) -> bool:\n",
        "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
        "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
        "\n",
        "shuffle(tweets)\n",
        "for tweet in tweets[:10]:\n",
        "    print(\">\", is_positive(tweet), tweet)\n",
        "\n",
        "#nltk.download('movie_reviews')\n",
        "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
        "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
        "all_review_ids = positive_review_ids + negative_review_ids\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> False RT @Those3Amigos: 'Secret' Tory plans for £8bn in welfare cuts exposed by Danny Alexander http//t.co/94BqGpTXM8\n",
            "> False RT @mrmarksteel: Tomorrow Miliband will say 'let me tell you this, I'm not even voting for myself in case I do a deal with the SNP'.\n",
            "> True RT @BBCPolitics: David Cameron says child benefit is \"key\" for UK families http//t.co/jsd8Jb1lYA #bbcqt http//t.co/c13CsAKr4Q\n",
            "> True Hi BAM ! @BarsAndMelody \n",
            "Can you follow my bestfriend @969Horan696 ? \n",
            "She loves you a lot :) \n",
            "See you in Warsaw &lt;3 \n",
            "Love you &lt;3 x39\n",
            "> False @LIAMREILLY20 I can ignore the journos, it's just if Cameron, Osborne or Clegg are on I fear for my TV with heavy objects close to hand\n",
            "> True @paynepowerr WITHOUT ME :(\n",
            "> True @NickTheBullsFan @CashNastyGaming still suck at editing but if this turns into something special I owe it to you guys :)\n",
            "> True @Michex69 @rich_falconer point is Tories will discredit SNP in England exploiting base nationalist instincts , labour is best bet !\n",
            "> False RT @thomasmessenger: For all Tories claiming that Labour overspent and thus caused a global financial crisis, ahem... http//t.co/DkLwCwzhDA\n",
            "> True RT @glenoglaza1: I know David Cameron likes quoting that Liam Byrne letter ad nauseum but it was supposed to be a joke ' #bbcqt #notthedeba…\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}